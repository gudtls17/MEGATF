{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import xlrd\n",
    "from sklearn.preprocessing import normalize, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from pandas import DataFrame\n",
    "import scipy as sc\n",
    "from scipy import io\n",
    "from scipy.stats import pearsonr\n",
    "from os.path import join, exists, dirname, basename\n",
    "from glob import glob\n",
    "from brainspace import gradient\n",
    "from random import randint\n",
    "import nibabel as nib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PET-Neurosynth weighted mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurosynth_term_map_list = np.array([np.load(join(neurosynth_path, \"terms_ActivationMap\", f\"{activation_term[i]}_uniformity-test_z_FDR_0.01.npy\")) for i in range(len(activation_term))])\n",
    "neurosynth_term_map_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\"\"\"Path definition\"\"\"\n",
    "pet_path = \"X:/ADNI2GO3/PET_preprocessed/\"\n",
    "\n",
    "\"\"\"Load Atlas\"\"\"\n",
    "parcel = 200  \n",
    "\n",
    "# [NOTE] Load Atlas, check Atlas name\n",
    "Atlas = nib.load(join(atlas_path, f\"tpl-MNI152NLin6Asym_res-02_atlas-Schaefer2018_desc-{parcel}Parcels7Networks_dseg.nii.gz\")).get_fdata()  # Schaefer\n",
    "n_roi = int(np.max(Atlas))\n",
    "\n",
    "mmp_atlas = nib.load(join(atlas_path, 'tpl-MNI152NLin6Asym_res-02_atlas-HCP_dseg.nii.gz'))  # for finding cerebellum region\n",
    "mmp_atlas = mmp_atlas .get_fdata()\n",
    "cerebellum_idx = np.where((mmp_atlas == 8)| (mmp_atlas == 47),)\n",
    "\n",
    "print(\"Atlas shape: \", Atlas.shape)\n",
    "\n",
    "neurosynth_term_map_list_abs = np.abs(neurosynth_term_map_list)  # Neurosynth term map processing\n",
    "\n",
    "\"\"\"Extract Atlas mapping PET (AV45 or FBB)\"\"\"\n",
    "for i in range(len(demo[\"subject_id\"])):\n",
    "    print(f\"{i} / {len(demo['subject_id'])}\", '', end='', flush=True)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    sub_id = demo[\"subject_id\"].iloc[i]\n",
    "    pt_id = sub_id.split(\"_\")[0]\n",
    "    session_id = sub_id.split(\"_\")[1]\n",
    "    \n",
    "    av45_check = demo[\"AV45\"].iloc[i]\n",
    "    fbb_check = demo[\"FBB\"].iloc[i]\n",
    "    \n",
    "    # [NOTE] Set save path, check save name\n",
    "    save_path = join(main_path, f'Area/Data/ADNI/{pt_id}/{session_id}')\n",
    "    if not exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    print(pt_id, session_id, '', end='', flush=True)\n",
    "    \n",
    "    if i % 200==0:\n",
    "        clear_output(wait=True)  # clear cell output\n",
    "    \n",
    "    \"Check completed session\"\n",
    "    feature_file = glob(join(save_path, f'SUVR_CL_Neurosynth_wmean_Scha{parcel}_Volume.npy'))\n",
    "    if len(feature_file) != 0:\n",
    "        print('Already completed') # already\n",
    "        continue\n",
    "    \n",
    "    \"\"\"Check PET file\"\"\"\n",
    "    nii_av45_file = glob(join(f\"{pet_path}/{pt_id}/{session_id}/acq-av45/*task-rest_acq-av45_pet_MNI.nii.gz\"))\n",
    "    nii_fbb_file = glob(join(f\"{pet_path}/{pt_id}/{session_id}/acq-fbb/*task-rest_acq-fbb_pet_MNI.nii.gz\"))\n",
    "    \n",
    "    SUVR_CL_voxel_list = []\n",
    "    if len(nii_av45_file) !=0:\n",
    "        nii_file = nii_av45_file\n",
    "        mid_name = 'av45'\n",
    "        \n",
    "        cl_param1 = 196.9  # For centiloid unit calculation \n",
    "        cl_param2 = 196.03\n",
    "        print(\"AV45\", ' ', end='', flush=True)\n",
    "        \n",
    "        dt = nib.load(nii_file[0])\n",
    "    \n",
    "        # if i % 200==0:\n",
    "        #     clear_output(wait=True)  # clear cell output\n",
    "        pet_voxel = dt.get_fdata()\n",
    "        # print(pet_voxel.shape)\n",
    "        reference_SUV = np.mean(pet_voxel[cerebellum_idx])\n",
    "\n",
    "        SUVR_voxel = pet_voxel/reference_SUV\n",
    "        SUVR_CL_voxel = (cl_param1*SUVR_voxel) - cl_param2\n",
    "        SUVR_CL_voxel_list.append(SUVR_CL_voxel)\n",
    "        \n",
    "    if len(nii_fbb_file) !=0:\n",
    "        nii_file = nii_fbb_file\n",
    "        mid_name = 'fbb'\n",
    "        \n",
    "        cl_param1 = 159.08 # For centiloid unit calculation \n",
    "        cl_param2 = 151.65\n",
    "        print(\"FBB\", ' ', end='', flush=True)\n",
    "        \n",
    "        dt = nib.load(nii_file[0])\n",
    "    \n",
    "        # if i % 200==0:\n",
    "        #     clear_output(wait=True)  # clear cell output\n",
    "        pet_voxel = dt.get_fdata()\n",
    "        # print(pet_voxel.shape)\n",
    "        reference_SUV = np.mean(pet_voxel[cerebellum_idx])\n",
    "\n",
    "        SUVR_voxel = pet_voxel/reference_SUV\n",
    "        SUVR_CL_voxel = (cl_param1*SUVR_voxel) - cl_param2\n",
    "        SUVR_CL_voxel_list.append(SUVR_CL_voxel)\n",
    "        \n",
    "    \n",
    "    if len(nii_av45_file) == 0 and len(nii_fbb_file) == 0:\n",
    "        print('Pass') # no nii file exist\n",
    "        continue\n",
    "    \n",
    "    SUVR_CL_voxel = np.array((SUVR_CL_voxel_list)).mean(axis=0)  # SUVR centiloid unit\n",
    "    SUVR_CL_weighted_voxel = np.array([SUVR_CL_voxel/200 * neurosynth_term_map_list_abs[i] for i in range(len(neurosynth_term_map_list_abs))]) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"Caculate each ROI noded feature (PET-Neurosynth correlation)\"\"\"\n",
    "    pet_neurosynth_r_feature = np.zeros((n_roi, len(neurosynth_term_map_list)))  # (ROI, Num of term)\n",
    "    pet_neurosynth_cossim_feature = np.zeros((n_roi, len(neurosynth_term_map_list)))  # (ROI, Num of term)\n",
    "    pet_neurosynth_wmean_feature = np.zeros((n_roi, len(neurosynth_term_map_list)))  # (ROI, Num of term)\n",
    "    for roi in range(1, n_roi+1):\n",
    "        idx = np.where(Atlas==roi)\n",
    "        \n",
    "        pet_neurosynth_wmean_feature[roi-1, :] = SUVR_CL_weighted_voxel[:, idx[0], idx[1], idx[2]].sum(axis=1) / neurosynth_term_map_list_abs[:, idx[0], idx[1], idx[2]].sum(axis=1)  # weighted mean\n",
    "    pet_neurosynth_wmean_feature = np.nan_to_num(pet_neurosynth_wmean_feature)\n",
    "    \n",
    "    \"\"\"Make pet-neurosynth connectivity matrix\"\"\"\n",
    "    pet_neurosynth_wmean_connectivity = np.corrcoef(pet_neurosynth_wmean_feature)\n",
    "    \n",
    "    np.save(join(save_path, f'SUVR_CL_Neurosynth_wmean_Scha{parcel}_Volume.npy'), pet_neurosynth_wmean_feature)  # (ROI, Num of term)\n",
    "    \n",
    "    np.save(join(save_path, f'SUVR_CL_Neurosynth_wmean_connmat_Scha{parcel}_Volume.npy'), pet_neurosynth_wmean_connectivity)  # (ROI, ROI)\n",
    "    \n",
    "    print(f' {time.time() - start_time} seconds!')\n",
    "    \n",
    "    # break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chs_pye37_neurosynth",
   "language": "python",
   "name": "chs_py37_neurosynth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
